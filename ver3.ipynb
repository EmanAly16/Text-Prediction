{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pprint, time\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data=list(nltk.corpus.treebank.tagged_sents())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95823\n",
      "71512\n",
      "4853\n",
      "3673\n"
     ]
    }
   ],
   "source": [
    "train_set,test_set=train_test_split(data,train_size=0.95,test_size=0.05)\n",
    "train_words=[tup[0] for sent in train_set for tup in sent]\n",
    "test_words=[tup[0] for sent in test_set for tup in sent]\n",
    "Ntrain = [word for word in train_words if word.isalpha()]\n",
    "lowerTrain = [word.lower() for word in Ntrain]\n",
    "Ntest = [word for word in test_words if word.isalpha()]\n",
    "lowerTest = [word.lower() for word in Ntest]\n",
    "print(len(train_words))\n",
    "print(len(lowerTrain))\n",
    "print(len(test_words))\n",
    "print(len(lowerTest))\n",
    "#print(lowerTest)\n",
    "#print(lowerTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8909\n"
     ]
    }
   ],
   "source": [
    "train_vocab_set=set(lowerTrain)\n",
    "print(len(train_vocab_set))\n",
    "#print(train_vocab_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t2_given_t1(t2,t1,train_bag=train_words): # tags=toks  tag=tok\n",
    "    \n",
    "    toks=[pair[0] for pair in train_bag]\n",
    "    \n",
    "    t1_toks_list=[tok for tok in toks if tok ==t1]\n",
    "    t1_tok_count=len(t1_toks_list)\n",
    "    \n",
    "    t2_given_t1_list=[toks[index+1] for index in range(len(toks)-1) if toks[index] == t1 and toks[index+1] == t2]\n",
    "    t2_given_t1_count=len(t2_given_t1_list)\n",
    "    return(t2_given_t1_count, t1_tok_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_matrix=np.zeros((len_train_words,len_train_words),dtype='float32')\n",
    "for i, t1 in enumerate(list(train_vocab_set)):\n",
    "    for j, t2 in enumerate(list(train_vocab_set)):\n",
    "        tok_matrix[i,j]=(t2_given_t1(t2,t1)[0])/(t2_given_t1(t2,t1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_df=pd.DataFrame(tok_matrix,columns=list(train_words),index=list(train_words))\n",
    "tok_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
